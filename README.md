## MNIST_MLP
**Design and implementation of a Multi Layer Perceptron (MLP).**

---

Generally, in the ML world, a feedforward neural network architecture is referred to as a Multi-layer perceptron (MLP) it is mainly composed of an input layer associated with one or more hidden and output layers
A closer look at a specific hidden or output layer shows the computation process operated once the input is received from the previous layer. it appears in the figure below that, the node computes the weighted sum of the received input following by the application of the non-linear activation function over the weighted sum and finally passes the result to the next connected node. The iteration of this process over the entire network results in the final output. implemented a multi-layer perceptron that classifies the MNIST handwritten digit and Fashion MNIST dataset
>For further information about multilayer perceptron networks, please read [Link](http://https://en.wikipedia.org/wiki/Multilayer_perceptron "Perceptron Network")

---

**Implementation result**

![plot](FashionMNIST\result.png)

![plot](MNIST\2.PNG)



